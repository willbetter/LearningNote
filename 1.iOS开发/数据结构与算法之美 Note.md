# 1.为什么要学习数据结构与算法

1. 为了通关大厂面试: 大厂面试都喜欢考算法, 现场写代码. 为了不跪在算法上, 需要好好学.
2. 不甘愿一辈子做业务代码: 虽然写业务代码的人很少需要自己实现数据结构和算法, 大部分时候都是使用别人的方法和框架. 但是不需要自己实现并不意味着什么都不需要了解. 写业务代码用到的很多第三方库都柔和了很多基础的数据结构和算法设计思想. 掌握数据结构与算法, 对于理解其背后设计思想非常有用. 理解第三方框架原理才能更好的使用第三方开源库.
3. 基础架构研发工程师,写出开源水平框架才是你的目标: 作为基础架构研发工程师, 只有了解数据结构和算法, 才能写出更好的基础组件.
4. 对编程的追求: 如果不想被行业淘汰, 就不要只写凑合能用的代码. 性能, 简装性, 可扩展性都是很重要的考量指标.

**掌握数据结构与算法, 你在看待问题的深度, 解决问题的角度都会完全不一样.** 这样的你, 就想式站在巨人的肩膀上, 拿着生存利器行走世界. 数据结构和算法, 会为你的编程之路, 甚至人生之路打开一扇通向新世界的大门. 

# 2.如何抓住重点, 高效的学习数据结构与算法
数据结构就是指一组数据的存储结构. 算法是操作数据的一组方法. 数据结构和算法是相辅相成的, 数据结构是为算法服务的, 算法要作用在特定的数据结构之上. 因此, 我们无法孤立数据结构来讲算法, 也不发孤立算法来讲数据结构.

要想掌握数据结构与算法, **最重要的是: 掌握复杂度分析.** 它有多重要呢? 几乎占据数据结构与算法的半壁江山. 

数据结构与算法知识点如下图所示:

![](images/913e0ababe43a2d57267df5c5f0832a7.jpg)

这里有王峥老师推荐的20个最常用的最基础的数据结构与算法, 不管事应付面试还是工作需要, 只要逐一功课这20个知识点就足够了. 10个数据结构:数组,链表,栈,队列,散列表,二叉树,堆,跳表,图,Trie树; 10个算法:递归算法,排序,二分查找,搜索,哈希算法,贪心算法,分治算法,回溯算法,动态规划,字符串匹配算法.

事半功倍的学习技巧:

1. 边学边练,适度刷题: 把每节课上涉及到的习题都自己敲一遍. 对于刷题, 一定要适度, 海量的刷题可能反而会导致你对数据结构和算法失去信心.
2. 多问,多思考,多互动: 不懂得有疑问的地方, 找人一块学习探讨.
3. 知识需要沉淀, 不要想视图一下子掌握所有: 学习知识的过程是反复迭代不断沉淀的过程, 看不懂就反复看,反复练, 自己搞不懂的就问别人, 问google.

# 3.算法的复杂度分析
## 3.1 什么是时间复杂度
**复杂度分析是这个那个算法学习的精髓, 只要掌握了它, 数据结构与算法的内容基本上就掌握了一半.**

**为什么需要复杂度分析?** 因为真机上测试结果非常依赖测试环境, 同样算法在不同cpu/内存上运行时间可能不同. 测试的结果受数据规模的影响比较大, 如果数据规模非常大, 根本无法在真机上进行实际测试(比如跑一遍需要数年的算法). 

我们需要一个不用具体的测试数据来测试, 就可以粗略估计算法执行效率的方法. 这就是时间/空间复杂度分析方法.

## 3.2 大O复杂度表示法
大O时间复杂度实际上并不具体表示代码真正的执行事件, 而是表示**代码执行时间随数据规模增长的变化趋势**, 因此也称为**渐进时间复杂度**, 简称时间复杂度.

**如何分析一个算法时间复杂度?** 

1. 只关注循环次数最多的一段代码. 大O时间复杂度表示的是一种变化趋势, 我们通常会忽略掉公式中的常量, 低阶, 系数, 只要记录一个最大阶的量级就可以了. **所以我们在分析一个算法, 一段代码的时间复杂度时候, 只关注循环此书最多的一段代码就可以了**.
2. 加法法则:**总时间复杂度等于量级最大的那段代码的复杂度.** 
3. 乘法法则:**嵌套代码的复杂度等于嵌套内外代码复杂度的乘积.**

## 3.3 几种常见的事件复杂度分析示例
![](images/3723793cc5c810e9d5b06bc95325bf0a.jpg)

1. **O(1):**一般情况下, 只要算法不存在循环, 递归, 即使有成千上万行的代码, 其时间复杂度也是O(1).
2. **O(log n),O(n\*log n):**2^x=n 则x=log2n. 这也是比较常见的时间复杂度, 归并排序,快速排序的时间复杂度都是O(nlogn).
3. **O(m+n),O(m\*n):**当无法确定m和n的量级哪个更大时候, 则两者都要考虑.

## 3.4 最好/最坏时间复杂度
顾名思义, **最好时间复杂度指最理想情况下, 执行代码的时间复杂度. 最坏时间复杂度指最糟糕情况下, 执行代码的时间复杂度.**

## 3.5 平均时间复杂度
**平均时间复杂度全称是加权平均时间复杂度或者期望时间复杂度.** 是使用概率论中方法计算出来的时间复杂度.

大多数情况下, 我们并不需要区分最好/最坏/平局时间复杂度. 只有同一块代码在不同情况下, 时间复杂度有量级的差距, 我们才会使用这三种复杂度表示来区分.

## 3.6 均摊时间复杂度
**使用摊还分析法得到的时间复杂度叫做均摊时间复杂度.**

实际上**均摊时间复杂度就是一种特殊的平均时间复杂度**, 我们没必要话费太多精力区分它们. 关键是掌握它的分析方法: **摊还分析法.**

## 3.7 空间复杂度
**空间复杂度实际上是渐进空间复杂度. 表示的是算法的存储空间随着数据规模之间的增长关系.**

## 3.8小结

集中时间复杂度的渐进增长图:

![](images/497a3f120b7debee07dc0d03984faf04.jpg)

# 4.数组:为什么很多编程语言数组都从0开始?
**数组是一种线性表数据结构. 它用一组连续的内存空间, 来存储一组具有相同类型的数据.** 

**线性表:** 线性表是指数据排成一条线一样的结构. 每个线性表的数据最多只有向前和向后来给你个方向. 除了数组, 链表, 队列, 栈等都是线性表.  **非线性表:** 二叉树, 图堆等. 之所以叫非线性表, 因为数据之间并不是简单的前后关系.

**连续内存空间相同数据类型:** 正是因为有了这两个特性, 它才有了堪称杀手锏的特性: **随机访问.**

数组随机访问的特性带来的缺点就是低效的插入和删除. 因为插入和查出设计到数据的移动. 

容器最大的好处是可以将很多数组操作的细节封装起来, 比如插入删除时候的数据移动. 另外容器一般支持动态扩容. **如果我们事先知道数组的最大容量, 那么我们最好指定数组的容量, 这样可以避免数据搬迁带来的额外开支.
**

**为什么数组编号从0开始呢?** 从数组存储的内存模型上看, 下标最确切的定义应该是"偏移". 因此使用0开头会更好一点. 更大的可能是历史原因造成的, C语言设计者使用0开始数组下标, 之后其它语言都效仿了C语言.

# 5.链表:如何实现LRU缓存淘汰算法
缓存是一种提高数据读取性能的技术, 在计算机领域有着广泛的应用. 缓存大小有限, 当缓存被用满时, 哪些数据被清除, 哪些被保留需要缓存淘汰策略决定. 常见的策略有三种: **先进先出策略FIFO**(First In, First Out), **最少使用策略LFU**(Least Frequently Used), **最近最少使用策略LRU**(Least Recently Used).

**链表相关概念:**

链表通过指针将一组零散的内存块串联在一起. 我们把内存块称为链表的**结点**. 内存块中记录链上下一个结点地址的指针称为**后继指针**, 记录前一个结点的指针叫做**前驱指针**. 我们习惯把链表的第一个结点称为**头结点**, 把最后一个结点称为**尾结点**. 尾结点指向头结点的链表称为**循环链表**. 

**如何实现一个LRU淘汰算法?**

思路: 维护一个有序单链表, 越靠近链表尾部的结点是越早之前访问的. 当有新的数据被访问时, 我们从链表头开始顺序遍历链表.

1. 如果此数据之前已经被缓存在链表中了, 我们得到这个数据对应的结点, 将其从原来的位置删除, 然后再插入到链表的头部. 
2. 如果吃数据没有在缓存列表中. 如果此时缓存未满, 则将结点插入到链表头部; 如果链表已满,则删除尾结点并将数据插入到头部.

以上LRU的实现, 不管结点是否存在都需要遍历一遍, 查找时间复杂度是O(n), 这里可以使用哈希表的方式进行缓存, 可以更快速的查找.

CPU在读取数据时候, 会把读到的数据加到CPU缓存中, 而cpu每次从内存中读取数据并不是只读取特定的地址, 而是读取一个数据块并保存在cpu缓存中, 然后下载访问就会先从cpu缓存中取, 取不到再去内存中取. 数组占用内存空间是连续的, 可能一次性读取多个数据到cpu缓存中, 而链表数据是不连续的, 无法享受到cpu缓存机制带来的好处.

# 6.链表:如何轻松正确的写出链表代码

1. 理解指针和应用的含义. 将某个变量赋值给指针时机上就是将这个变量的地址赋值给指针, 或者反过来说, 指针中村村了这个变量的内存地址, 指向这个变量, 通过指针就能找到这个变量.
2. 警惕指针丢失和内存泄露. 在插入或者删除结点时候一定要注意插入或者删除的顺序, 谨防指针丢失.
3. 利用哨兵简化实现难度. 针对链表的插入/删除操作, 需要对插入的第一个结点和删除最后一个结点情况特殊处理, 这样实现起来繁琐不简洁. 我们可以针对性的引入**哨兵结点**(包含哨兵结点的链表称为带头链表). 
4. 重点关注边界条件. 空链表能否正常运行? 一个结点是否正常? 两个结点是否正常? 处理头结点和尾结点是否正常?
5. 举例画图,辅助思考. 想不明白的地方, 多举例画图, 更加直观.
6. 多写多练. 

# 7.栈:实现浏览器的前进后退功能
## 7.1 栈的基本概念
后进先出,先进后出,这就是典型的栈结构. 从栈的操作特性上看, **栈是一种"操作受限"的线性表**. 当某个数据集合只设计在一端插入和删除数据,并且满足后进先出,先进后出的特性,我们就应该首选栈这种数据结构.

栈可以用数组实现, 也可以用链表实现. **用数组实现的栈叫顺序栈**, **用链表实现的栈叫做链式栈**.

**支持动态扩容的顺序栈**. 如果存储数据的数组支持动态扩容, 那么这个栈就可以支持动态扩容.

## 7.2 栈的应用

* **栈在函数调用中的应用**. 操作系统给每个线程分配一个独立的内存空间, 这块内存空间被组织成栈这种结构, 用来存储函数调用时的临时变量. 每进入一个函数, 就会将临时变量作为一个栈桢入栈, 当调用函数完成, 将这个函数对应的栈桢出栈.
* **栈在表达式求值中的应用**. 实际上编译期通过两个栈来实现表达式的求值. 其中一个保存操作数的栈, 另一个保存运算符的栈. 从左到右遍历表达式, 遇到数字就压入数据栈, 遇到操作符就与最顶层的进行比较. 如果比运算符栈顶部元素优先级高, 就将当前运算符压入栈; 反之则取出栈顶运算符, 取出两个操作数进行计算, 将结果压入操作数栈后继续进行比较.
* **栈在括号匹配中的应用**. 左括号入栈,右括号出栈, 最终栈是空的则括号是匹配的.

## 7.3 如何实现浏览器的前进后退功能?
方法1: 使用两个栈,如下图所示. 每打开一个页面将页面入栈到X栈中, 后退时候将X栈栈顶元素出栈并放到Y栈中. 前进时候从Y栈取栈顶元素放入X栈. 如果X栈入栈新的页面, 则清空Y栈.

![](images/4b579a76ea7ebfc5abae2ad6ae6a3c3d.jpg)

方法2: 数组存储页面. 指定两个指针, x指针表示当前正在展示的页面, y指针表示最深能够达到的页面. 打开新页面时候移动x,移动y. 当返回时候x指针后退. 前进时候x前进并判断x<=y时候可前进. 当打开新页面时候,移动x,重置y=x.

# 8.队列
队列也是一种操作受限的线性表结构. 使用数组实现的队列叫做顺序队列. 使用链表实现的队列叫做链式队列. 队列需要两个指针head和tail.

循环队列: 首尾相连组成一个环的队列叫做循环队列. 循环队列可以使用数组实现.

队列最大的特点是先进先出, 主要有两个操作, 入队和出队. 可以用数组实现也可以用链表实现.

阻塞队列和并发队列, 底层都是队列这种数据结构, 只不过在之上附加了其它功能. 阻塞队列就是入队/出队操作可以阻塞. 并发队列就是队列的操作多线程安全(通过加锁的方式实现).

# 9.递归
## 9.1 递归基础
只要问题可以满足三个条件, 就可以使用递归来解决:

1. 一个问题的解可以分解为几个子问题的解;
2. 这个问题和分解之后的子问题, 除了数据规模不同, 求解思路完全相同;
3. 存在递归终止条件;

写递归代码最重要的是**写出递归公式, 找到递归终止条件.** 写递归代码的关键是找到如何将大问题分解为小问题的规律, 并且基于此写出递归公式, 然后再推敲出终止条件, 最后将递推公式和终止条件翻译成代码.

**编写递归关键是, 只要遇到递归, 我们就把它抽象成一个递推公司, 不用想一层一层的调用关系, 不要视图用人脑取分解递归的每个步骤.** 事实证明, 人脑并不擅长分解, 倒推, 但这确是计算机的长项.

## 9.2 递归注意事项
* 警惕堆栈溢出: 如果递归深度过深, 则可能导致函数调用栈溢出. 我们可以限制递归的调用深度来防止溢出; 另外通过堆上模拟栈调用也可以用来防止堆栈溢出.
* 递归代码警惕重复计算: 比如青蛙跳台阶的问题, 如下图所示. 事实上f(2)/f(1)会计算多次, 这会导致重复计算, 我们可以使用哈希表将对应的结果存储起来, 以此避免重复计算.

![](images/e7e778994e90265344f6ac9da39e01bf.jpg)

# 10.排序
排序算法种类繁多, 但是常用的比较少: 冒泡排序, 插入排序, 选择排序, 归并排序, 快速排序, 计数排序, 基数排序, 桶排序. 其时间复杂度如下所示:

![](images/fb8394a588b12ff6695cfd664afb17cd.jpg)

## 10.1 如何分析排序算法
1. 最好/最坏/平均时间复杂度. 我们通过评估算法最好/最坏/平均时间复杂度来区分, 因为即使相同平均时间复杂度其还是会有差别的. 其次有的数据接近有序,有的数据完全无序, 我们需要知道算法在不同数据下的性能表现.
2. 时间复杂度的系数, 常数, 低阶. 时间复杂度表示的是一个增长趋势, 它忽略了系数, 低阶, 常数, 但是在实际开发中, 我们经常对很小规模数据排序, 这时候需要把系数/低阶/常数考虑进去.
3. 比较次数和移动次数. 对于小规模的数据排序, 我们需要考虑到算法的比较次数和移动次数.

**原地排序:** 原地排序是指空间复杂度是O(1)的排序算法.

**稳定性:** 稳定性指, 如果排序的序列中存在值相等的元素, 经过排序后, 相等元素之间原有的先后顺序不变.

## 10.2 冒泡排序
**冒泡排序**: 操作相邻的两个数据. 每次冒泡对相邻的两个数据进行比较, 看是否满足大小关系需要. 如果不满足就进行交换. 一次冒泡会让至少一个元素移动到它应该在的位置, 重复n次,就完成了n个数据的排序. 

优化: 当某次冒泡没有数据交换时候, 说明已经达到完全有序, 不需要继续执行后续冒泡操作了.

冒泡排序是一种原地排序算法, 是稳定的排序算法, 最好时间复杂度是O(1), 最坏时间复杂度是O(n^2).

冒泡排序的swift实现:

```
// bubble sort
func bubbleSort(_ nums: inout [Int]) {
    guard false == nums.isEmpty else { return }
    
    let count = nums.count
    for i in 0..<count {
        let tail = count - 1 - i
        for j in 0..<tail {
            if nums[j] > nums[j + 1] {
                (nums[j], nums[j + 1]) = (nums[j + 1], nums[j])
            }
        }
    }
}
```

## 10.3 插入排序
**插入排序**: 我们将数组中数据分为两个区间, 已排序区间和未排序区间. 初始已排序区间只有一个元素, 就是数组的第一个元素. 插入排序的核心思想是取未排序区间的元素, 在已排序区间中找到合适的为止进行插入, 并保证已排序区间数据一直有序. 重复此过程, 直到未排序区间为空.

插入排序是一种原地排序算法, 是稳定的排序算法, 最好时间复杂度是O(n), 最坏时间复杂度是O(n^2).

插入排序的Swift实现:
```
// insertion sort
func insertionSort(_ nums: inout [Int]) {
    guard nums.count > 1 else { return }
    
    for i in 1..<nums.count {
        let temp = nums[i]
        var j = i - 1
        while j >= 0 && nums[j] > temp {
            nums[j + 1] = nums[j]
            j = j - 1
        }
        if j != i - 1 {
            nums[j + 1] = temp
        }
    }
}
```
## 10.4 选择排序
**选择排序**: 选择排序类似插入排序, 也分为已排序区间和未排序区间. 但选择排序是每次从未排序区间中找到最小的元素, 将其放到已排序区间的末尾.

选择排序是原地排序, **不稳定排序**(数据交换导致前后顺序发生变化), 其最好, 最坏, 平均时间复杂度都是O(n^2). 

选择排序swift实现:

```
// selection sort
func selectionSort(_ nums: inout [Int]) {
    guard false == nums.isEmpty else { return }
    
    let count = nums.count
    for i in 0..<count {
        var minIndex = i
        for j in (i + 1)..<count {
            if nums[minIndex] > nums[j] {
                minIndex = j
            }
        }
        if i != minIndex {
            (nums[minIndex], nums[i]) = (nums[i], nums[minIndex])
        }
    }
}
```

冒泡排序和选择排序在实际开发中应用比较少.学习目的只是为了拓展思维. 但是插入排序还是比较有用的. 某些编程语言的排序函数实现原理会用到插入排序.

## 10.5 希尔排序
**希尔排序**: 把记录按照下标的一定增量分组, 对每组使用直接插入排序算法排序; 随着增量组件减少, 每组包含的关键词越来越多, 当增量减至1时, 整个文件恰被分成一组, 算法终止. 

希尔排序是原地排序, 不稳定排序(分组交换会破坏稳定性), 平均时间复杂度O(n^2)的的算法. 是**基于插入排序的优化版本**.

希尔排序过程(来自[wikipedia](https://zh.wikipedia.org/wiki/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F)):

![](images/Sorting_shellsort_anim.gif)

希尔排序的swift实现:

```
```

## 10.6 归并排序
归并排序: 如果要排序一个数组, 先把数组从中间分成前后两部分, 然后对前后两部分分别排序, 再将排好序的两部分合并在一起, 这样整个数组就都是有序的了. 

归并排序采用分治思想. 将一个大问题分解成小的子问题来解决. 小问题解决了, 大问题自然就解决了. **分治是一种解决问题的处理思想, 递归是一种编程思想.** 

归并排序的示意图如下所示:

![](images/db7f892d3355ef74da9cd64aa926dc2b.jpg)

归并排序是否是稳定排序要看`merge()`函数, 归并排序可以是稳定的排序. 归并排序时间复杂度是O(nlog n). 归并排序的空间复杂度是O(n).

归并排序的swift实现

```swift
```

## 10.7 快速排序
快速排序(快排QuickSort): 快排也是利用分治思想. 从要排序数组中选择一个数据作为分区点. 遍历数组, 将小于分区点的数据放在左边, 将大于分区点的数据放在右边, 重复此步骤. 最终整个数组就是有序的了.

快速排序涉及到分区和数据交换, 因此会破坏数据原有的顺序, 快排是不稳定的排序. 是一种原地排序算法. 大部分情况下时间复杂度都可以做到O(nlog n), 但是极端情况下会退化到O(n^2)(比如对于一个有序的数组, 每次选择其第一个元素,则时间复杂度会退化到O(n^2)). 

**快速排序和归并排序区别:**

![](images/aa03ae570dace416127c9ccf9db8ac05.jpg)

如图所示, 归并排序的处理过程是由**下到上的**, 先处理子问题, 再合并. 快排恰好相反, **由上到下**, 先进行分区, 然后以此对每个分区进行排序.

快速排序的swift实现:

```swift
```

## 10.8 桶排序
桶排序: 如果要排序的数据有n个, 我们把它均匀的划分到m个桶中, 每个桶内有k=n/m个元素. 每个桶内使用快速排序, 时间复杂度是O(klogk), m个桶排序的时间复杂度是O(`m*k*logk`)因为 k=n/m，所以整个桶排序的时间复杂度就是O(nlog(n/m)). 当桶的个数m接近数据个数n时, log(n/m)就是一个非常小的常量, 这个时候桶排序的时间复杂度接近O(n). 

桶排序对排序数据的要求非常苛刻. 首先数据需要很容易划分成m个桶, 并且桶和桶之间有着天然的大小顺序. 这样每个桶内数据排序完成之后, 桶桶之间数据不再需要进行排序. 

其次数据在各个桶之间的分布是比较均匀的. 如果不均匀, 比如极端情况下数据都在一个桶内, 则算法就会退化到O(nlogn). 

**场景:** 桶排序比较适合用在外部排序. 外部排序就是数据存乎在外部磁盘中, 数据量比较大, 内存有限, 无法将数据全部加载到内存中.

## 10.9 计数排序
计数排序是桶排序的一种特殊情况. 当要排序的n歌数据, 所处的范围不大时候, 比如最大k, 我们可以把数据划分成k个桶. 每个桶内的数据值是相同的, 省掉了桶内排序的时间.

**计数排序步骤:**

1. 遍历要排序的数组A, 使用数组C按照桶排序的规则在C内记录每个数据出现的次数;
2. 数组C从前到后以此累加;
3. 遍历数组A, 从C中取出对应value的个数, 其个数即为计数排序中其排序数组中的位置.
4. 根据找到的位置, 在数组R的对应位置存放数据, 将C中对应的value-1.

**总结:** 计数排序只能用在数据范围不大的场景中, 如果数据范围k比要排序的数据n大很多, 就不适合计数排序了. 而且, 计数排序只能给非负整数排序, 如果要排序的数据是其它类型, 则需要在不改变相对大小的情况下, 转化为非负整数.

计数排序swift实现:

```swift
计数排序实现:
假设我们现在需要对 D，a，F，B，c，A，z 这个字符串进行排序，要求将其中所有小写字母都排在大写字母的前面，但小写字母内部和大写字母内部不要求有序。比如经过排序之后为 a，c，z，D，F，B，A，这个如何来实现呢？如果字符串中存储的不仅有大小写字母，还有数字。要将小写字母的放到前面，大写字母放在最后，数字放在中间，不用排序算法，又该怎么解决呢？

```

## 10.10 基数排序
基数排序: 基数排序对要排序数据是有要求的, 需要可以分割出独立的位来来比较, 而且位之间有递进关系, 如果a数据的高位比b数据大, 那剩下的低位就不需要比较了. 除此之外, 每一位的数据范围不能太大, 要可以用线性排序算法来排序, 否则基数排序的时间复杂度就没办法做到O(n).

以对10万个手机号排序为例. 借助稳定排序算法, 我们先按照最后一位来排序手机号码, 然后按照倒数第二位重新排序, 经过11次排序后, 手机号码就都有序了. 需要注意的是, 这里按位排序的算法必须是稳定的, 否则先对低位进行排序就没有意义!

**扩展:** 有时候, 数据长度是不同的, 这时候我们可以对较短的数据末位进行补零, 不影响最后结果.

# 11.排序优化:实现一个通用的,高性能的排序函数
几种排序算法基本信息如下所示:

![](images/1f6ef7e0a5365d6e9d68f0ccc71755fd.jpg)

线性排序算法时间复杂度低, 但是适用场景有限. 所以通用的排序函数, 不能选择线性排序算法. 

对小规模数据进行排序, 可以选择时间复杂度O(n^2)的算法; 如果对大规模数据进行排序, 时间复杂度O(nlogn)的算法更加高效.

归并排序使用的并不多, 因为归并排序并不是原地排序算法, 空间复杂度O(n). 对于大规模的数据, 很容易导致内存暴涨.

## 11.1 如何优化快速排序
如果数据本身是有序或者接近有序, 每次分区都选择最后一个数据, 那么快速排序算法就会变得非常糟糕, 时间复杂度就会退化成O(n^2). 这主要是因为我们分区点选择不够合理造成的. **最理想的分区点, 被分开的两个分区中, 数据的数量差不多.**

两种常用的,简单的分区算法:

1. **三数取中法**. 从分区的首/尾/中各取一个点, 比较大小, 取中值作为分区点.
2. **随机法**. 随机从要排序区间内选择一个元素作为分区点.

## 11.2 举例分析排序函数
Glibc中的qsort()函数. 它并不仅仅是快速排序算法实现的, qsort()会优先使用归并排序来排序输入数据, 因为归并排序的空间复杂度是O(n), 所以对于小规模的数据排序问题不大. 这是个典型**空间换时间**的技巧; 当要排序的数据量很大时候, 就会采用快速排序算法来排序(使用三点取中法选择分区点); qsort()还用到了插入排序, 当数据个数小于4时候, qsort()就退化成了插入排序. 






























